{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hrishicrnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_MnDsa7Ylaj",
        "colab_type": "code",
        "outputId": "8051e8d0-7890-4f7a-c309-f2fad71108a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d2G3L4T---Zs",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/BeautyJudge/CRNet/model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLmN8Jtwbc4H",
        "colab_type": "code",
        "outputId": "f74e71a0-c186-4d38-ff5d-138467ec326b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls *.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__.py  losses.py\tmodels.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhgHOyhpcTJ8",
        "colab_type": "code",
        "outputId": "91528c6b-215d-40cd-c276-b3bbb9b1456c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " !cat '/content/drive/My Drive/BeautyJudge/CRNet/model/models.py'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "from torchvision import models\n",
            "\n",
            "\n",
            "class CRNet(nn.Module):\n",
            "    \"\"\"\n",
            "    definition of CRNet\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self):\n",
            "        super(CRNet, self).__init__()\n",
            "        self.meta = {'mean': [131.45376586914062, 103.98748016357422, 91.46234893798828],\n",
            "                     'std': [1, 1, 1],\n",
            "                     'imageSize': [224, 224, 3]}\n",
            "\n",
            "        model_ft = models.resnet18(pretrained=True)\n",
            "\n",
            "        self.model = model_ft\n",
            "        self.regressor = Regressor(model_ft)\n",
            "        self.classifier = Classifier(model_ft, num_cls=5)\n",
            "\n",
            "    def forward(self, x):\n",
            "        for name, module in self.model.named_children():\n",
            "            if name != 'fc':\n",
            "                x = module(x)\n",
            "\n",
            "        reg_out = self.regressor.forward(x.view(-1, self.num_flat_features(x)))\n",
            "        cls_out = self.classifier.forward(x.view(-1, self.num_flat_features(x)))\n",
            "\n",
            "        return reg_out, cls_out\n",
            "\n",
            "    def num_flat_features(self, x):\n",
            "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
            "        num_features = 1\n",
            "        for s in size:\n",
            "            num_features *= s\n",
            "\n",
            "        return num_features\n",
            "\n",
            "\n",
            "class Regressor(nn.Module):\n",
            "\n",
            "    def __init__(self, model):\n",
            "        super(Regressor, self).__init__()\n",
            "\n",
            "        num_ftrs = model.fc.in_features\n",
            "        self.fc1 = nn.Linear(num_ftrs, 256)\n",
            "        self.fc2 = nn.Linear(256, 64)\n",
            "        self.fc3 = nn.Linear(64, 1)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x1 = F.relu(self.fc1(x))\n",
            "        x1 = F.dropout(x1, p=0.5, training=self.training)\n",
            "        x2 = F.relu(self.fc2(x1))\n",
            "        x2 = F.dropout(x2, p=0.5, training=self.training)\n",
            "        x3 = self.fc3(x2)\n",
            "\n",
            "        return x3\n",
            "\n",
            "    def num_flat_features(self, x):\n",
            "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
            "        num_features = 1\n",
            "        for s in size:\n",
            "            num_features *= s\n",
            "\n",
            "        return num_features\n",
            "\n",
            "\n",
            "class Classifier(nn.Module):\n",
            "\n",
            "    def __init__(self, model, num_cls=5):\n",
            "        super(Classifier, self).__init__()\n",
            "\n",
            "        num_ftrs = model.fc.in_features\n",
            "        self.fc1 = nn.Linear(num_ftrs, 256)\n",
            "        self.fc2 = nn.Linear(256, 64)\n",
            "        self.fc3 = nn.Linear(64, num_cls)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x1 = F.relu(self.fc1(x))\n",
            "        x1 = F.dropout(x1, p=0.5, training=self.training)\n",
            "        x2 = F.relu(self.fc2(x1))\n",
            "        x2 = F.dropout(x2, p=0.5, training=self.training)\n",
            "        x3 = self.fc3(x2)\n",
            "\n",
            "        return x3\n",
            "\n",
            "    def num_flat_features(self, x):\n",
            "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
            "        num_features = 1\n",
            "        for s in size:\n",
            "            num_features *= s\n",
            "\n",
            "        return num_features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTd5Xhc5dpCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/T&H/DL Project/CRNet/main')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBGbZYPN95CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5nhcFEpYCmM",
        "colab_type": "code",
        "outputId": "63751f22-3a8b-4b01-d294-4bdc1ca63bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sys.path.append('../')\n",
        "from model.models import CRNet\n",
        "from config.cfg import cfg\n",
        "\n",
        "\n",
        "def viz(img_path, model=CRNet()):\n",
        "    model = model.float()\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "        model = nn.DataParallel(model)\n",
        "    os.chdir('/content/drive/My Drive/BeautyJudge/CRNet/')\n",
        "    !ls\n",
        "    model = nn.DataParallel(model)\n",
        "    model.load_state_dict(torch.load('./model/crnet.pth'))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    image = resize(io.imread(img_path), (224, 224), mode='constant')\n",
        "    image[:, :, 0] -= np.mean(image[:, :, 0])\n",
        "    image[:, :, 1] -= np.mean(image[:, :, 1])\n",
        "    image[:, :, 2] -= np.mean(image[:, :, 2])\n",
        "\n",
        "    image = np.transpose(image, [2, 0, 1])\n",
        "    input = torch.from_numpy(image).unsqueeze(0).float()\n",
        "    input = input.to(device)\n",
        "\n",
        "    for idx, module in model.named_children():\n",
        "        if idx == 'model':\n",
        "            for idx, mod in module.named_children():\n",
        "                # print(idx)\n",
        "                if idx != 'avgpool':\n",
        "                    input = mod(input)\n",
        "                else:\n",
        "                    # mat = np.transpose(input[0, [1, 1, 1], :, :].data.cpu().numpy(), [1, 2, 0])\n",
        "                    mat = np.transpose(input[0, :, :, :].data.cpu().numpy(), [1, 2, 0])\n",
        "                    mat = np.mean(mat, axis=2).reshape([mat.shape[0], mat.shape[0], 1])\n",
        "                    print(mat.shape)\n",
        "                    # mat = resize(mat, (224, 224), mode='constant')\n",
        "                    mat = cv2.resize(mat, (224, 224))\n",
        "                    org = resize(io.imread(img_path), (224, 224), mode='constant')\n",
        "\n",
        "                    dst = np.zeros([224, 224, 3])\n",
        "                    dst[:, :, 0] = 0.2 * org[:, :, 0] + 0.8 * mat\n",
        "                    dst[:, :, 1] = 0.2 * org[:, :, 1] + 0.8 * mat\n",
        "                    dst[:, :, 2] = 0.2 * org[:, :, 2] + 0.8 * mat\n",
        "\n",
        "                    # dst = org + mat\n",
        "\n",
        "                    # plt.figure(\"Image\")\n",
        "                    # plt.imshow(org)\n",
        "                    # plt.axis('on')\n",
        "                    # plt.title('image')\n",
        "                    # plt.show()\n",
        "\n",
        "                    # cv2.imshow('ft', dst)\n",
        "                    # cv2.waitKey()\n",
        "\n",
        "                    if not os.path.exists('./feature_viz/'):\n",
        "                        os.makedirs('./feature_viz/')\n",
        "\n",
        "                    scipy.misc.imsave('./feature_viz/' + os.path.basename(img_path).split('.')[0] + '.jpg', dst)\n",
        "                    break\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.chdir('/content/drive/My Drive/BeautyJudge/CRNet')\n",
        "    !ls\n",
        "    filelist = [\"feature_viz/\"+\"SCUT-FBP-%d.jpg\" % _ for _ in [101, 57, 242, 380, 192, 469, 241, 174]]\n",
        "    print(filelist)\n",
        "    for f in filelist:\n",
        "        viz(f, CRNet())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 156MB/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "['feature_viz/SCUT-FBP-101.jpg', 'feature_viz/SCUT-FBP-57.jpg', 'feature_viz/SCUT-FBP-242.jpg', 'feature_viz/SCUT-FBP-380.jpg', 'feature_viz/SCUT-FBP-192.jpg', 'feature_viz/SCUT-FBP-469.jpg', 'feature_viz/SCUT-FBP-241.jpg', 'feature_viz/SCUT-FBP-174.jpg']\n",
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hLrjLRhNX3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/BeautyJudge/CRNet/main')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRUYAdGPInmC",
        "colab_type": "code",
        "outputId": "4d0fa8b5-07f1-4155-e65a-641b9805a579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, transforms\n",
        "\n",
        "sys.path.append('../')\n",
        "from model.models import CRNet\n",
        "from model.losses import CRLoss\n",
        "from data.data_loder import ScutFBPDataset, HotOrNotDataset, BeautyGAN\n",
        "from util.utils import mkdirs_if_not_exist\n",
        "from config.cfg import cfg\n",
        "\n",
        "\n",
        "def train_model(model, train_dataloader, test_dataloader, pred_dataloader,criterion, optimizer, scheduler, num_epochs=25,\n",
        "                inference=False):\n",
        "    model = model.float()\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "        model = nn.DataParallel(model)\n",
        "    model = model.to(device)\n",
        "\n",
        "    if not inference:\n",
        "        print('Start training CRNet...')\n",
        "        os.chdir('/content/drive/My Drive/BeautyJudge/CRNet/Crop_unzip/Crop')\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(train_dataloader, 0):\n",
        "                inputs, scores, classes = data['image'], data['score'], data['class']\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                scores = scores.to(device)\n",
        "                classes = classes.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                inputs = inputs.float()\n",
        "                scores = scores.float().view(cfg['batch_size'], 1)\n",
        "                # classes = classes.int().view(cfg['batch_size'], 3)\n",
        "\n",
        "                reg_out, cls_out = model(inputs)\n",
        "                loss = criterion(cls_out, classes, reg_out, scores)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                running_loss += loss.item()\n",
        "                if i % 10 == 9:  # print every 10 mini-batches\n",
        "                    print('[%d, %5d] loss: %.3f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 10))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        print('Finished training CRNet...\\n')\n",
        "        print('Saving trained model...')\n",
        "        model_path_dir = './model'\n",
        "        mkdirs_if_not_exist(model_path_dir)\n",
        "        torch.save(model.state_dict(), os.path.join(model_path_dir, 'crnet.pth'))\n",
        "        print('CRNet has been saved successfully~')\n",
        "\n",
        "    else:\n",
        "        print('Loading pre-trained model...')\n",
        "        model.load_state_dict(torch.load(os.path.join('./model/crnet.pth')))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    print('Start testing CRNet...')\n",
        "    predicted_labels = []\n",
        "    gt_labels = []\n",
        "    filenames = []\n",
        "    for data in test_dataloader:\n",
        "        images, scores, classes, filename = data['image'], data['score'], data['class'], data['filename']\n",
        "        images = images.to(device)\n",
        "\n",
        "        reg_out, cls_out = model.forward(images)\n",
        "\n",
        "        # bat_list = []\n",
        "        # for out in F.softmax(cls_out).to(\"cpu\"):\n",
        "        #     tmp = 0\n",
        "        #     for i in range(0, 3, 1):\n",
        "        #         tmp += out[i] * (i - 1)\n",
        "        #     bat_list.append(float(tmp.detach().numpy()))\n",
        "\n",
        "        # predicted_labels += (0.6 * reg_out.to(\"cpu\").detach().numpy() + 0.4 * np.array(bat_list)).tolist()\n",
        "\n",
        "        predicted_labels += reg_out.to(\"cpu\").detach().numpy().tolist()\n",
        "        gt_labels += scores.to(\"cpu\").detach().numpy().tolist()\n",
        "        filenames += filename\n",
        "\n",
        "    print('Start predicting data...')\n",
        "    preds = []\n",
        "    pred_filenames=[]\n",
        "    for data in pred_dataloader:\n",
        "        images_pred, filename_pred = data['image'], data['filename']\n",
        "        images_pred = images_pred.to(device)\n",
        "\n",
        "        reg_out, cls_out = model.forward(images_pred)\n",
        "\n",
        "        preds += reg_out.to(\"cpu\").detach().numpy().tolist()\n",
        "        pred_filenames += filename_pred\n",
        "\n",
        "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "    mae_lr = round(mean_absolute_error(np.array(gt_labels), np.array(predicted_labels).ravel()), 4)\n",
        "    rmse_lr = round(np.math.sqrt(mean_squared_error(np.array(gt_labels), np.array(predicted_labels).ravel())), 4)\n",
        "    pc = round(np.corrcoef(np.array(gt_labels), np.array(predicted_labels).ravel())[0, 1], 4)\n",
        "\n",
        "    print('===============The Mean Absolute Error of CRNet is {0}===================='.format(mae_lr))\n",
        "    print('===============The Root Mean Square Error of CRNet is {0}===================='.format(rmse_lr))\n",
        "    print('===============The Pearson Correlation of CRNet is {0}===================='.format(pc))\n",
        "\n",
        "    col = ['filename', 'gt', 'pred']\n",
        "    df = pd.DataFrame([[filenames[i], gt_labels[i], predicted_labels[i][0]] for i in range(len(gt_labels))],\n",
        "                      columns=col)\n",
        "    df.to_excel(\"./output.xlsx\", sheet_name='Output', index=False)\n",
        "    print('Output Excel has been generated~')\n",
        "\n",
        "    cols_pred = ['filename', 'pred']\n",
        "    df = pd.DataFrame([[pred_filenames[i], preds[i]] for i in range(len(preds))],\n",
        "                      columns=cols_pred)\n",
        "    df.to_excel(\"./output_beautygan.xlsx\", sheet_name='Output', index=False)\n",
        "    print('Pred Output Excel has been generated~')\n",
        "\n",
        "\n",
        "def run_crnet_scutfbp(model, epoch=30):\n",
        "    criterion = CRLoss()\n",
        "\n",
        "    optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\n",
        "    os.chdir('/content/drive/My Drive/BeautyJudge/CRNet/')\n",
        "    !ls\n",
        "    df = pd.read_excel('cvsplit/SCUT-FBP.xlsx', sheet_name='Sheet1')\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['Image'].tolist(), df['Attractiveness label'],\n",
        "                                                        test_size=0.2, random_state=0)\n",
        "\n",
        "    print('start loading SCUT-FBP dataset...')\n",
        "    train_dataset = ScutFBPDataset(f_list=X_train, f_labels=y_train, transform=transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                             std=[1, 1, 1])\n",
        "    ]))\n",
        "\n",
        "    test_dataset = ScutFBPDataset(f_list=X_test, f_labels=y_test, transform=transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                             std=[1, 1, 1])\n",
        "    ]))\n",
        "\n",
        "    pred_list=[x for x in range(1126)]\n",
        "\n",
        "    pred_dataset = BeautyGAN(f_list=pred_list, transform=transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                             std=[1, 1, 1])\n",
        "    ]))\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=cfg['batch_size'],\n",
        "                                  shuffle=True, num_workers=4)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=cfg['batch_size'],\n",
        "                                 shuffle=False, num_workers=4)\n",
        "    \n",
        "    pred_dataloader = DataLoader(pred_dataset, batch_size=cfg['batch_size'],\n",
        "                                 shuffle=False, num_workers=4)\n",
        "\n",
        "    print('finish loading SCUT-FBP dataset...')\n",
        "    train_model(model=model, train_dataloader=train_dataloader, test_dataloader=test_dataloader, \n",
        "                pred_dataloader=pred_dataloader,criterion=criterion, optimizer=optimizer_ft, scheduler=exp_lr_scheduler, num_epochs=epoch,\n",
        "                inference=False)\n",
        "\n",
        "\n",
        "def run_crnet_eccv(model, cv_split=1, epoch=30):\n",
        "    \"\"\"\n",
        "    train and test ECCV HotOrNot dataset\n",
        "    :param cv_split:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    criterion = CRLoss()\n",
        "\n",
        "    optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\n",
        "\n",
        "    print('start loading ECCV HotOrNot dataset...')\n",
        "    train_dataset = HotOrNotDataset(cv_split=cv_split, train=True, transform=transforms.Compose([\n",
        "        transforms.Resize(227),\n",
        "        transforms.RandomCrop(224),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                             std=[1, 1, 1])\n",
        "    ]))\n",
        "\n",
        "    test_dataset = HotOrNotDataset(cv_split=cv_split, train=False, transform=transforms.Compose([\n",
        "        transforms.Resize(227),\n",
        "        transforms.RandomCrop(224),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5,0.5],\n",
        "                             std=[1, 1, 1,1])\n",
        "    ]))\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=cfg['batch_size'],\n",
        "                                  shuffle=True, num_workers=4, drop_last=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=cfg['batch_size'],\n",
        "                                 shuffle=False, num_workers=4, drop_last=True)\n",
        "\n",
        "    print('finish loading ECCV HotOrNot dataset...')\n",
        "\n",
        "    train_model(model=model, train_dataloader=train_dataloader, test_dataloader=test_dataloader,\n",
        "                criterion=criterion, optimizer=optimizer_ft, scheduler=exp_lr_scheduler, num_epochs=epoch,\n",
        "                inference=False)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_crnet_scutfbp(model=CRNet(), epoch=30)\n",
        "    # run_crnet_eccv(model=CRNet(), cv_split=1, epoch=30)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BeautyGanCrop  Crop.zip  deep_feature.png  main       scutfbp.png\n",
            "config\t       cvsplit\t feature_viz\t   model      util\n",
            "Crop_unzip     data\t LICENSE\t   README.md\n",
            "start loading SCUT-FBP dataset...\n",
            "finish loading SCUT-FBP dataset...\n",
            "Start training CRNet...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 4.165\n",
            "[1,    20] loss: 1.719\n",
            "[2,    10] loss: 1.367\n",
            "[2,    20] loss: 1.249\n",
            "[3,    10] loss: 1.033\n",
            "[3,    20] loss: 1.092\n",
            "[4,    10] loss: 0.839\n",
            "[4,    20] loss: 0.986\n",
            "[5,    10] loss: 0.910\n",
            "[5,    20] loss: 0.753\n",
            "[6,    10] loss: 0.745\n",
            "[6,    20] loss: 0.734\n",
            "[7,    10] loss: 0.774\n",
            "[7,    20] loss: 0.785\n",
            "[8,    10] loss: 0.773\n",
            "[8,    20] loss: 0.754\n",
            "[9,    10] loss: 0.690\n",
            "[9,    20] loss: 0.679\n",
            "[10,    10] loss: 0.625\n",
            "[10,    20] loss: 0.637\n",
            "[11,    10] loss: 0.667\n",
            "[11,    20] loss: 0.582\n",
            "[12,    10] loss: 0.641\n",
            "[12,    20] loss: 0.562\n",
            "[13,    10] loss: 0.604\n",
            "[13,    20] loss: 0.585\n",
            "[14,    10] loss: 0.496\n",
            "[14,    20] loss: 0.613\n",
            "[15,    10] loss: 0.574\n",
            "[15,    20] loss: 0.573\n",
            "[16,    10] loss: 0.552\n",
            "[16,    20] loss: 0.551\n",
            "[17,    10] loss: 0.547\n",
            "[17,    20] loss: 0.521\n",
            "[18,    10] loss: 0.515\n",
            "[18,    20] loss: 0.525\n",
            "[19,    10] loss: 0.470\n",
            "[19,    20] loss: 0.509\n",
            "[20,    10] loss: 0.501\n",
            "[20,    20] loss: 0.456\n",
            "[21,    10] loss: 0.434\n",
            "[21,    20] loss: 0.481\n",
            "[22,    10] loss: 0.466\n",
            "[22,    20] loss: 0.479\n",
            "[23,    10] loss: 0.471\n",
            "[23,    20] loss: 0.430\n",
            "[24,    10] loss: 0.502\n",
            "[24,    20] loss: 0.466\n",
            "[25,    10] loss: 0.525\n",
            "[25,    20] loss: 0.471\n",
            "[26,    10] loss: 0.438\n",
            "[26,    20] loss: 0.499\n",
            "[27,    10] loss: 0.470\n",
            "[27,    20] loss: 0.457\n",
            "[28,    10] loss: 0.501\n",
            "[28,    20] loss: 0.458\n",
            "[29,    10] loss: 0.440\n",
            "[29,    20] loss: 0.448\n",
            "[30,    10] loss: 0.531\n",
            "[30,    20] loss: 0.454\n",
            "Finished training CRNet...\n",
            "\n",
            "Saving trained model...\n",
            "CRNet has been saved successfully~\n",
            "Start testing CRNet...\n",
            "Start predicting data...\n",
            "===============The Mean Absolute Error of CRNet is 0.2548====================\n",
            "===============The Root Mean Square Error of CRNet is 0.3226====================\n",
            "===============The Pearson Correlation of CRNet is 0.8773====================\n",
            "Output Excel has been generated~\n",
            "Pred Output Excel has been generated~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbomNzg_RP1K",
        "colab_type": "code",
        "outputId": "068e4a97-585a-4576-e1c6-a7ef10438468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(os.path)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'posixpath' from '/usr/lib/python3.6/posixpath.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "022TsUNnaRhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}